{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58b7515c",
   "metadata": {},
   "source": [
    "nn.Module로구현하는선형회귀-single data 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b3a7db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409593d6",
   "metadata": {},
   "source": [
    "#훈련데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "60c4f35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "x_data=torch.FloatTensor([[1],[2],[3],[4],[5]])\n",
    "t_data=torch.FloatTensor([[3],[5],[7],[9],[11]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdba9b7c",
   "metadata": {},
   "source": [
    "모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bbded120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[0.5153]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.4414], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "model=nn.Linear(1,1) # input_dim=1, output_dim=1\n",
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c911fb",
   "metadata": {},
   "source": [
    "최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c2d95df",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5e2ac8",
   "metadata": {},
   "source": [
    "학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4eb7c2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Cost: 39.16685104370117\n",
      "Epoch: 400 Cost: 0.01109258271753788\n",
      "Epoch: 800 Cost: 0.0007385412463918328\n",
      "Epoch: 1200 Cost: 4.91717473778408e-05\n",
      "Epoch: 1600 Cost: 3.276181814726442e-06\n",
      "Epoch: 2000 Cost: 2.1860606125301274e-07\n",
      "Epoch: 2400 Cost: 1.4702209227834828e-08\n",
      "Epoch: 2800 Cost: 9.986707016906848e-10\n",
      "Epoch: 3200 Cost: 1.0809344391793374e-10\n",
      "Epoch: 3600 Cost: 5.426272625674855e-11\n",
      "Epoch: 4000 Cost: 5.426272625674855e-11\n",
      "Epoch: 4400 Cost: 5.426272625674855e-11\n",
      "Epoch: 4800 Cost: 5.426272625674855e-11\n",
      "Epoch: 5200 Cost: 5.426272625674855e-11\n",
      "Epoch: 5600 Cost: 5.426272625674855e-11\n",
      "Epoch: 6000 Cost: 5.426272625674855e-11\n",
      "Epoch: 6400 Cost: 5.426272625674855e-11\n",
      "Epoch: 6800 Cost: 5.426272625674855e-11\n",
      "Epoch: 7200 Cost: 5.426272625674855e-11\n",
      "Epoch: 7600 Cost: 5.426272625674855e-11\n",
      "Epoch: 8000 Cost: 5.426272625674855e-11\n",
      "Epoch: 8400 Cost: 5.426272625674855e-11\n",
      "Epoch: 8800 Cost: 5.426272625674855e-11\n",
      "Epoch: 9200 Cost: 5.426272625674855e-11\n",
      "Epoch: 9600 Cost: 5.426272625674855e-11\n",
      "Epoch: 10000 Cost: 5.426272625674855e-11\n",
      "Epoch: 10400 Cost: 5.426272625674855e-11\n",
      "Epoch: 10800 Cost: 5.426272625674855e-11\n",
      "Epoch: 11200 Cost: 5.426272625674855e-11\n",
      "Epoch: 11600 Cost: 5.426272625674855e-11\n",
      "Epoch: 12000 Cost: 5.426272625674855e-11\n",
      "Epoch: 12400 Cost: 5.426272625674855e-11\n",
      "Epoch: 12800 Cost: 5.426272625674855e-11\n",
      "Epoch: 13200 Cost: 5.426272625674855e-11\n",
      "Epoch: 13600 Cost: 5.426272625674855e-11\n",
      "Epoch: 14000 Cost: 5.426272625674855e-11\n",
      "Epoch: 14400 Cost: 5.426272625674855e-11\n",
      "Epoch: 14800 Cost: 5.426272625674855e-11\n",
      "Epoch: 15200 Cost: 5.426272625674855e-11\n",
      "Epoch: 15600 Cost: 5.426272625674855e-11\n",
      "Epoch: 16000 Cost: 5.426272625674855e-11\n",
      "Epoch: 16400 Cost: 5.426272625674855e-11\n",
      "Epoch: 16800 Cost: 5.426272625674855e-11\n",
      "Epoch: 17200 Cost: 5.426272625674855e-11\n",
      "Epoch: 17600 Cost: 5.426272625674855e-11\n",
      "Epoch: 18000 Cost: 5.426272625674855e-11\n",
      "Epoch: 18400 Cost: 5.426272625674855e-11\n",
      "Epoch: 18800 Cost: 5.426272625674855e-11\n",
      "Epoch: 19200 Cost: 5.426272625674855e-11\n",
      "Epoch: 19600 Cost: 5.426272625674855e-11\n"
     ]
    }
   ],
   "source": [
    "nb_epochs=20000\n",
    "for epoch in range(nb_epochs):\n",
    "    prediction=model(x_data)\n",
    "    cost=F.mse_loss(prediction, t_data)\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    if epoch%400==0:\n",
    "      print('Epoch:', epoch, 'Cost:',cost.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a830389f",
   "metadata": {},
   "source": [
    "예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "351dc93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[21.0000]], grad_fn=<AddmmBackward0>)\n",
      "[Parameter containing:\n",
      "tensor([[2.0000]], requires_grad=True), Parameter containing:\n",
      "tensor([1.0000], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "new_data=torch.FloatTensor([[10]])\n",
    "y_pred=model(new_data)\n",
    "print(y_pred)\n",
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8553561",
   "metadata": {},
   "source": [
    "nn.Module로 구현하는 선형 회귀- multi data 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d05efe",
   "metadata": {},
   "source": [
    "실습예제1 해보자 따로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d10f533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터\n",
    "x_train = torch.FloatTensor([[73, 80, 75],\n",
    "                            [93, 88, 93],\n",
    "                            [89, 91, 90],\n",
    "                            [96, 98, 100],\n",
    "                            [73, 66, 70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bfd1e3",
   "metadata": {},
   "source": [
    "모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bdbb95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49bef4a3",
   "metadata": {},
   "source": [
    "실습예제2\n",
    "data/data-01-test-socre.csv\n",
    "파일을 사용하여 다중 선형회귀분석을 수행해라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e843ea5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>73</th>\n",
       "      <th>80</th>\n",
       "      <th>75</th>\n",
       "      <th>152</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93</td>\n",
       "      <td>88</td>\n",
       "      <td>93</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89</td>\n",
       "      <td>91</td>\n",
       "      <td>90</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96</td>\n",
       "      <td>98</td>\n",
       "      <td>100</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>73</td>\n",
       "      <td>66</td>\n",
       "      <td>70</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53</td>\n",
       "      <td>46</td>\n",
       "      <td>55</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>69</td>\n",
       "      <td>74</td>\n",
       "      <td>77</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>47</td>\n",
       "      <td>56</td>\n",
       "      <td>60</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>87</td>\n",
       "      <td>79</td>\n",
       "      <td>90</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>79</td>\n",
       "      <td>70</td>\n",
       "      <td>88</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>69</td>\n",
       "      <td>70</td>\n",
       "      <td>73</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>70</td>\n",
       "      <td>65</td>\n",
       "      <td>74</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>93</td>\n",
       "      <td>95</td>\n",
       "      <td>91</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>79</td>\n",
       "      <td>80</td>\n",
       "      <td>73</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>70</td>\n",
       "      <td>73</td>\n",
       "      <td>78</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>93</td>\n",
       "      <td>89</td>\n",
       "      <td>96</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>78</td>\n",
       "      <td>75</td>\n",
       "      <td>68</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>81</td>\n",
       "      <td>90</td>\n",
       "      <td>93</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>88</td>\n",
       "      <td>92</td>\n",
       "      <td>86</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>78</td>\n",
       "      <td>83</td>\n",
       "      <td>77</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>82</td>\n",
       "      <td>86</td>\n",
       "      <td>90</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>86</td>\n",
       "      <td>82</td>\n",
       "      <td>89</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>78</td>\n",
       "      <td>83</td>\n",
       "      <td>85</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>76</td>\n",
       "      <td>83</td>\n",
       "      <td>71</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>96</td>\n",
       "      <td>93</td>\n",
       "      <td>95</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    73  80   75  152\n",
       "0   93  88   93  185\n",
       "1   89  91   90  180\n",
       "2   96  98  100  196\n",
       "3   73  66   70  142\n",
       "4   53  46   55  101\n",
       "5   69  74   77  149\n",
       "6   47  56   60  115\n",
       "7   87  79   90  175\n",
       "8   79  70   88  164\n",
       "9   69  70   73  141\n",
       "10  70  65   74  141\n",
       "11  93  95   91  184\n",
       "12  79  80   73  152\n",
       "13  70  73   78  148\n",
       "14  93  89   96  192\n",
       "15  78  75   68  147\n",
       "16  81  90   93  183\n",
       "17  88  92   86  177\n",
       "18  78  83   77  159\n",
       "19  82  86   90  177\n",
       "20  86  82   89  175\n",
       "21  78  83   85  175\n",
       "22  76  83   71  149\n",
       "23  96  93   95  192"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('../data02/data-01-test-score.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846e0cb5",
   "metadata": {},
   "source": [
    "훈련 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0220f61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: tensor([[ 93.,  88.,  93.],\n",
      "        [ 89.,  91.,  90.],\n",
      "        [ 96.,  98., 100.],\n",
      "        [ 73.,  66.,  70.],\n",
      "        [ 53.,  46.,  55.],\n",
      "        [ 69.,  74.,  77.],\n",
      "        [ 47.,  56.,  60.],\n",
      "        [ 87.,  79.,  90.],\n",
      "        [ 79.,  70.,  88.],\n",
      "        [ 69.,  70.,  73.],\n",
      "        [ 70.,  65.,  74.],\n",
      "        [ 93.,  95.,  91.],\n",
      "        [ 79.,  80.,  73.],\n",
      "        [ 70.,  73.,  78.],\n",
      "        [ 93.,  89.,  96.],\n",
      "        [ 78.,  75.,  68.],\n",
      "        [ 81.,  90.,  93.],\n",
      "        [ 88.,  92.,  86.],\n",
      "        [ 78.,  83.,  77.],\n",
      "        [ 82.,  86.,  90.],\n",
      "        [ 86.,  82.,  89.],\n",
      "        [ 78.,  83.,  85.],\n",
      "        [ 76.,  83.,  71.],\n",
      "        [ 96.,  93.,  95.]])\n",
      "y_train: tensor([185., 180., 196., 142., 101., 149., 115., 175., 164., 141., 141., 184.,\n",
      "        152., 148., 192., 147., 183., 177., 159., 177., 175., 175., 149., 192.])\n",
      "x_train.shape: torch.Size([24, 3])\n",
      "y_train.shape: torch.Size([24])\n"
     ]
    }
   ],
   "source": [
    "x_train = torch.tensor(df.values[:,:-1], dtype=torch.float32)\n",
    "y_train = torch.tensor(df.values[:,-1], dtype=torch.float32)\n",
    "print(\"x_train:\", x_train)\n",
    "print(\"y_train:\", y_train)\n",
    "print(\"x_train.shape:\", x_train.shape)\n",
    "print(\"y_train.shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cf9d9bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = nn.Linear(3,1)\n",
    "# print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8825a2",
   "metadata": {},
   "source": [
    "#자동 코드\n",
    "input_dim = x_data.shape[1]\n",
    "output_dim = 1\n",
    "\n",
    "model = nn.Linear(input_dim, output_dim)\n",
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188e6cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a32650b",
   "metadata": {},
   "source": [
    "print(list(model.parameters()))는 아래의 의미\n",
    "y=w1​x1​+w2​x2​+...+wn​xn​+b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a087ac8f",
   "metadata": {},
   "source": [
    "Class 활용\n",
    "아래의 두 데이터를 활용해서 하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "08a45b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(x_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfec1a39",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected np.ndarray (got Tensor)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x_data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(x_data)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m      2\u001b[0m y_data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(y_data)\u001b[38;5;241m.\u001b[39mfloat()\n",
      "\u001b[1;31mTypeError\u001b[0m: expected np.ndarray (got Tensor)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6378fbe",
   "metadata": {},
   "source": [
    "class 만들기\n",
    "class 이름은 내 마음대로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e5c5b7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "  def __inti__(self):\n",
    "    super().__init__() #파이썬은 init이 생성자고, super class를 생성한다는 말???? ㅇㅁㅇ??? 부른다는 말????\n",
    "    self.linear=nn.Linear(3,1)\n",
    "#모델 완성\n",
    "\n",
    "#학습할때 부르는 함수 생성\n",
    "  def forward(self, x):\n",
    "    return self.linear(x) #x데이터를 넣으면 이 함수를 호출함.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec99e1d8",
   "metadata": {},
   "source": [
    "모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "390a010b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegressionModel()\n",
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9cb82eb8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "optimizer got an empty parameter list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m)\n\u001b[0;32m      2\u001b[0m epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50001\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\it\\anaconda3\\Lib\\site-packages\\torch\\optim\\sgd.py:65\u001b[0m, in \u001b[0;36mSGD.__init__\u001b[1;34m(self, params, lr, momentum, dampening, weight_decay, nesterov, maximize, foreach, differentiable, fused)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nesterov \u001b[38;5;129;01mand\u001b[39;00m (momentum \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dampening \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNesterov momentum requires a momentum and zero dampening\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(params, defaults)\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fused:\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step_supports_amp_scaling \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\it\\anaconda3\\Lib\\site-packages\\torch\\optim\\optimizer.py:396\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[1;34m(self, params, defaults)\u001b[0m\n\u001b[0;32m    394\u001b[0m param_groups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(params)\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(param_groups) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 396\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer got an empty parameter list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(param_groups[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    398\u001b[0m     param_groups \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m: param_groups}]\n",
      "\u001b[1;31mValueError\u001b[0m: optimizer got an empty parameter list"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.0001)\n",
    "epochs=50001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71435fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "  y=model(x_data) #y와 b 값을 가진 model에 의해 나온 y값\n",
    "  cost=F.mse_loss(y-y_data)\n",
    "  optimizer.zero_grad() #for 문 돌면서 초기화\n",
    "\n",
    "  cost.backward() #기울기 계산\n",
    "  optimizer.step() #wb를 업데이트\n",
    "\n",
    "  if epoch%100 ==0:\n",
    "    print(f'epoch:{epoch}, cost:{cost.item}, w, b:{model.parameters()}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
