{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc9ae5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.init as init\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80448ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [00:10<00:00, 15.6MB/s] \n"
     ]
    }
   ],
   "source": [
    "cifar10_train = datasets.CIFAR10(root='../data02/cifar10_data',\n",
    "                                      train=True,\n",
    "                                      download=True,\n",
    "                                      transform=transforms.Compose([transforms.ToTensor()]))\n",
    "cifar10_test = datasets.CIFAR10(root='../data02/cifar10_data',\n",
    "                                      train=False,\n",
    "                                      download=True,\n",
    "                                      transform=transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39710630",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.manual_seed(0)\n",
    "if device =='cuda':\n",
    "  torch.cuda.manual_seed_all(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b6439aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "learning_rate = 0.001\n",
    "epochs = 10\n",
    "batch_size = 100\n",
    "\n",
    "lowest_loss = np.inf\n",
    "lowest_epoch = np.inf\n",
    "early_stop = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "308437ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=cifar10_train,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True)\n",
    "test_loader = DataLoader(dataset=cifar10_test,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68906436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 3, 32, 32]) torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "for x,y in train_loader:\n",
    "  print(x.size(), y.size())\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fc7d723",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    self.layer1 = nn.Sequential(\n",
    "      nn.Conv2d(3,32,3,1,1),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(2,2)\n",
    "    )\n",
    "    # image shape(100, 3, 32, 32)\n",
    "    # conv1 -> (3, 32, 32, 32)\n",
    "    # pool -> (3, 32, 16, 16)\n",
    "\n",
    "    self.layer2 = nn.Sequential(\n",
    "      nn.Conv2d(32,64,3,1,1),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(2,2)\n",
    "    )\n",
    "    # image shape(?, 32, 16, 16)\n",
    "    # conv1 -> (32, 64, 16, 16)\n",
    "    # pool -> (32, 64, 8, 8)\n",
    "\n",
    "    self.layer3 = nn.Sequential(\n",
    "      nn.Conv2d(64,128,3,1,1),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(2,2)\n",
    "    )\n",
    "\n",
    "    self.fc = nn.Sequential(\n",
    "      nn.Linear(128*4*4, 100, bias=True),\n",
    "      nn.LeakyReLU(),\n",
    "      nn.Linear(100,10,bias=True)\n",
    "    )\n",
    "    # nn.Linear(128*4*4, 100, bias=True)\n",
    "    # nn.init.xavier_uniform_(self.fc.weight)\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = self.layer1(x)\n",
    "    out = self.layer2(out)\n",
    "    out = self.layer3(out)\n",
    "    out = out.view(out.size(0),-1)\n",
    "    out = self.fc(out)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a151fdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98e9dc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_batch = len(train_loader)\n",
    "test_batch = len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7c6d992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, cost:1.5564669370651245\n",
      "epoch:1, cost:1.15193510055542\n",
      "epoch:2, cost:0.973167896270752\n",
      "epoch:3, cost:0.8463259339332581\n",
      "epoch:4, cost:0.7535978555679321\n",
      "epoch:5, cost:0.6764012575149536\n",
      "epoch:6, cost:0.6097567081451416\n",
      "epoch:7, cost:0.5525524616241455\n",
      "epoch:8, cost:0.4896961748600006\n",
      "epoch:9, cost:0.43710511922836304\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "  avg_cost = 0\n",
    "\n",
    "  for x, y in train_loader:\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    y_hat = model(x)\n",
    "    cost = criterion(y_hat, y)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    avg_cost += cost\n",
    "  avg_cost = avg_cost/total_batch\n",
    "  print(f'epoch:{epoch}, cost:{avg_cost}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ea5a046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.29000091552734\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "  avg_accuracy = 0\n",
    "\n",
    "  for x,y in test_loader:\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    pred = model(x)\n",
    "    correct_pred = torch.argmax(pred, -1) == y\n",
    "    accuracy = correct_pred.float().sum()\n",
    "    avg_accuracy += accuracy\n",
    "  avg_accuracy = avg_accuracy/test_batch\n",
    "\n",
    "print(f'Accuracy: {avg_accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
